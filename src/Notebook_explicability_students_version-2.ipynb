{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"avxIOU_3Ttg0"},"outputs":[],"source":["!pip install dalex --quiet\n","!pip install shap --quiet\n","!pip install lime --quiet\n","!pip install tensorflow --quiet\n","!pip install scikit-learn --quiet\n","!pip install matplotlib --quiet\n","!pip install pandas --quiet\n","!pip install numpy --quiet\n","!pip install xgboost --quiet # good boost libs: XGBoost, LightGBM, CatBoost"]},{"cell_type":"markdown","metadata":{"id":"osVwhgnjTi5A"},"source":["# Understand the standard tools for model explainability\n","\n","## Background\n","\n","\n","> Model explainability is a major issue for certain sectors such as insurance or banking in the validation and production of developed models. In certain situations, you will not only have to perform well but also be able to justify the decisions made by your model and explain the results. \n",">\n","> Let's take a concrete case from everyday life: the purchase of a property. Hélène wants to become the happy owner of an apartment in Paris, so she applies for a loan from her bank. A Data Scientist has recently developed, in collaboration with a Data Engineer, an application available to bank agents that is able to predict whether or not it is profitable to grant the loan, based on a few characteristics such as the person's gender. Hélène is refused a loan and surprised by the decision, she asks her bank for an explanation, which she is obliged to provide by detailing the strengths and weaknesses of Hélène's file. The bank must therefore be able to explain to Hélène which characteristics weighed positively and especially negatively in the rejection of her loan. This requires the data scientist to provide at least some figures or a graphical interface explaining the local situation of Helen. We will show that it is possible to use simple tools to answer this question. \n","> \n","> Behind the question of explaining the model's decision to Hélène are several issues, including :\n",">* Fairness: Ensuring that predictions are unbiased and do not implicitly or explicitly discriminate against underrepresented groups. An interpretable model can tell you why it has decided that a certain person should not get a loan, and it becomes easier for a human to judge whether the decision is based on a learned demographic (e.g. racial) bias.\n",">* Privacy: Ensuring that sensitive information in the data is protected.\n",">* Reliability or Robustness: Ensuring that small changes in the input do not lead to large changes in the prediction.\n",">* Causality: Check that only causal relationships are picked up.\n",">* Trust: It is easier for humans to trust a system that explains its decisions compared to a black box.\n","> \n","> Explainability aims to respond to these challenges and to bring confidence to the data scientists who model, to the businesses or to the users who use the model. It is a crucial point so that the people for whom you create the data product accept it and use it on a daily basis. \n","\n","## Model-specific or model-agnostic\n","\n","> Model-specific interpretation tools are limited to specific model classes. The interpretation of regression weights in a linear model is a model-specific interpretation, since – by definition – the interpretation of intrinsically interpretable models is always model-specific. Tools that only work for the interpretation of e.g. neural networks are model-specific. Model-agnostic tools can be used on any machine learning model and are applied after the model has been trained (post hoc). These agnostic methods usually work by analyzing feature input and output pairs. By definition, these methods cannot have access to model internals such as weights or structural information.\n",">\n","> The interpretation tools specific to the models may contradict each other depending on the specific criterion studied.\n","\n","## Local vs Global\n","\n","> When we talk about explainability, it is possible to try to explain the decision of the model for a particular individual or the global behavior of the model. The first option can for example help us to understand the errors of the model for a restricted group of observations, the second option to detect biases. \n",">\n","> Example realized on the **`housing.csv`** dataset."]},{"cell_type":"code","execution_count":1,"metadata":{"id":"Zbk6S5dtTi5I"},"outputs":[{"name":"stdout","output_type":"stream","text":["GradientBoosting score on train : 0.9997399292269133\n","RandomForest score on train : 0.9182912717141076\n","GradientBoosting score on test : 0.823128630171869\n","RandomForest score on test : 0.8040242936464083\n"]}],"source":["import pandas as pd\n","import dalex as dx\n","\n","from sklearn.ensemble import GradientBoostingRegressor\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.datasets import fetch_california_housing\n","from sklearn.model_selection import train_test_split\n","\n","X, y = fetch_california_housing(return_X_y=True, as_frame=True)\n","\n","X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=123)\n","\n","# print the first 5 rows of the dataset\n","print(X.head(5))\n","print(y.head(5))\n","\n","\n","clf_gb = GradientBoostingRegressor(n_estimators = 250, max_depth=12, random_state=1234)\n","clf_rf = RandomForestRegressor(n_estimators = 250, max_depth=12, random_state=1234)\n","\n","clf_gb.fit(X_train, y_train)\n","clf_rf.fit(X_train, y_train)\n","\n","print(\"GradientBoosting score on train :\", clf_gb.score(X_train, y_train))\n","print(\"RandomForest score on train :\", clf_rf.score(X_train, y_train))\n","\n","print(\"GradientBoosting score on test :\", clf_gb.score(X_test, y_test))\n","print(\"RandomForest score on test :\", clf_rf.score(X_test, y_test))"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["X samples: \n","    MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n","0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n","1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n","2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n","3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n","4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n","\n","   Longitude  \n","0    -122.23  \n","1    -122.22  \n","2    -122.24  \n","3    -122.25  \n","4    -122.25  \n","\n","y labels: \n"," 0    4.526\n","1    3.585\n","2    3.521\n","3    3.413\n","4    3.422\n","Name: MedHouseVal, dtype: float64\n"]}],"source":["# print the first 5 rows of the dataset\n","print(\"X samples: \\n\", X.head(5))\n","print()\n","print(\"y labels: \\n\", y[:5])"]},{"cell_type":"markdown","metadata":{"id":"CleBDR9nTi5K"},"source":["## Partial Dependence Plot (PDP)\n","\n","> The partial dependence plot is a global method: The method considers all instances and gives a statement about the global relationship of a feature with the predicted outcome.\n",">\n","> The partial function $\\hat{f}_{s}$ is estimated by calculating averages in the training data, also known as Monte Carlo method:\n","> <center> $\\hat{f}_{s}(x_s)=\\frac{1}{n}\\sum_{i=1}^{n}\\hat{f}(x_s, x_c^{(i)})$ </center>\n",">\n","> The partial function tells us for given value(s) of features S what the average marginal effect on the prediction is. In this formula, $x_c^{(i)}$ are actual feature values from the dataset for the features in which we are not interested, and n is the number of instances in the dataset. An assumption of the PDP is that the features in C are not correlated with the features in S. If this assumption is violated, the averages calculated for the partial dependence plot will include data points that are very unlikely or even impossible."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KtFrs1meTi5L"},"outputs":[],"source":["housing_gb_exp = dx.Explainer(clf_gb, X_train, y_train, \n","                  label = \"Housing gb\")\n","\n","pdp_gb = housing_gb_exp.model_profile(variables = [\"HouseAge\", 'MedInc'])\n","pdp_gb.plot()"]},{"cell_type":"markdown","metadata":{"id":"LEhU16HzTi5N"},"source":["## Permutation Importance\n","\n","> The permutation feature importance algorithm based on Fisher, Rudin, and Dominici (2018):\n",">\n","> Input: Trained model $\\hat{f}$, feature matrix $X$, target vector $y$, error measure $L(y,\\hat{f})$ :\n",">* Estimate the original model error $L(y,\\hat{f})$.\n",">* For each feature $j \\in (1,...,p)$ do:\n",">** Generate feature matrix $X_{perm}$ by permuting feature j in the data X. This breaks the association between feature j and true outcome y.\n",">** Estimate error $L(y,\\hat{f}(X_{perm}))$ based on the predictions of the permuted data.\n",">** Calculate permutation feature importance as difference $FI_j = L(y,\\hat{f}) - L(y,\\hat{f}(X_{perm}))$\n",">* Sort features by descending FI."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qIdCsl1zTi5O"},"outputs":[],"source":["housing_gb_exp = dx.Explainer(clf_gb, X_test, y_test, \n","                  label = \"Housing gb\")\n","\n","mp_gb = housing_gb_exp.model_parts(loss_function='r2')\n","mp_gb.plot()"]},{"cell_type":"markdown","metadata":{"id":"0nUb0Y5S_WTM"},"source":["#  LIME [(Ribeiro .al 2016)](https://arxiv.org/abs/1602.04938)\n","\n","## Intuition\n","*Intuitively, an explanation is a local linear approximation of the model's behaviour. While the model may be very complex globally, it is easier to approximate it around the vicinity of a particular instance. While treating the model as a black box, we perturb the instance we want to explain and learn a sparse linear model around it, as an explanation*\n","\n","<p align=\"center\">\n","<img src=https://raw.githubusercontent.com/marcotcr/lime/master/doc/images/lime.png width=400>\n","</p>"]},{"cell_type":"markdown","metadata":{"id":"M66ubXUJQbhv"},"source":["## Algorithm steps \n","The different steps computed by the algorithm are the following :\n","\n","### 1. Creation of a neighbourhood around the instance : \n","- Data samples are generated by applying perturbations around the instance following a normal distribution\n","- A weight is allocated to every sample with regard to its proximity to the instance. This is the crucial step. The instance explanations may differ a lot with regard to the kernel used to compute the weights. 2 variables are at stake here, the kernel function and the kernel width :\n","  - the kernel function $k$ :\n","  $$k(d, k_w) = exp(\\frac{-d^2}{k_w})$$ \n","  where $$d = \\sqrt{\\sum_{i}^{} (y_i - x_i)^2}$$\n","  - the kernel width $k_w$ :\n","$$k_w = 0.75*\\sqrt{n_f}$$ \n","with $n_f$ the number of features in the train set.\n","\n","$k$ and $k_w$ are 2 parameters of our LIME function and can be customised.\n","\n","An example of the impact of the kernel width on the instance explanation :\n","\n","<p align=\"center\">\n","<img src=https://christophm.github.io/interpretable-ml-book/images/lime-fail-1.png width=500>\n","</p>\n","\n","### 2. Generate the samples labels \n","Make black-box model predictions on the newly generated neighbourhood dataset to generate the associated labels.\n","\n","### 3. Fit a linear model on the samples\n","A linear model is then fitted to this labeled data in order to generate our local linear model which corresponds to our instance explanation"]},{"cell_type":"markdown","metadata":{"id":"hFAnT0nNOIx_"},"source":["# LIME for text\n","\n","LIME for text data has one major difference with LIME for tabular data : the way the samples are generated and their weights computed. Let's take again the first step of the algorithm, illustrated with a YouTube comments Spam classification model.\n","\n","|| CONTENT      | CLASS |\n","|-----------| ----------- | ----------- |\n","|267| PSY is a good guy      | 0       |\n","|173| For Christmas Song visit my channel! ;)   | 1        |\n","\n","### 1. Creation of a neighbourhoods around the instance : \n","\n","- Data samples are generated by randomly removing some words from the instance text. The neighbourhood dataset is a dataset a binary features, where the value is 1 if the corresponding word is included and 0 if it has been removed.\n","\n","| For |\tChristmas\t| Song |\tvisit |\tmy |\tchannel! |\t;) |\n","| -- | -- | -- | -- | -- | -- | -- |\n","|1|0|1|1|0|0|1|\n","|0|1|1|1|1|0|1|\n","|1|0|0|1|1|1|1|\n","|1|0|1|1|1|1|1|\n","|0|1|1|1|0|0|1|\n","\n","- A weight is allocated to every sample with regard to its proximity to the instance. With LIME for text, the weight is calculated with the same kernel than for tabular data, with a default kernel width of 25 (kernel width can be customised).\n","\n","| For |\tChristmas\t| Song |\tvisit |\tmy |\tchannel! |\t;) | weight |\n","| -- | -- | -- | -- | -- | -- | -- | -- |\n","|1|0|1|1|0|0|1|0.89|\n","|0|1|1|1|1|0|1|0.92|\n","|1|0|0|1|1|1|1|0.92|\n","|1|0|1|1|1|1|1|0.96|\n","|0|1|1|1|0|0|1|0.89|\n","\n","### 2. Generate the samples labels \n","\n","- This second step is very close to the one for tabular data. The class 1 probability is calculated for every sample using the black-box model's predictions.\n","\n","| For |\tChristmas\t| Song |\tvisit |\tmy |\tchannel! |\t;) | weight | prob |\n","| -- | -- | -- | -- | -- | -- | -- | -- | -- |\n","|1|0|1|1|0|0|1|0.89|0.17|\n","|0|1|1|1|1|0|1|0.92|0.17|\n","|1|0|0|1|1|1|1|0.92|0.99|\n","|1|0|1|1|1|1|1|0.96|0.99|\n","|0|1|1|1|0|0|1|0.89|0.17|\n","\n","### 3. Fit a linear model on the samples\n","- This third step remains the same, a linear model is then fitted to this labeled data in order to generate our local linear model which corresponds to our instance explanation."]},{"cell_type":"markdown","metadata":{"id":"S-6pbYBQbDE9"},"source":["# Now let's practice !"]},{"cell_type":"markdown","metadata":{"id":"DxoRJURjLRlC"},"source":["## Packages installation & Imports "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8v1uXHEZbNoj"},"outputs":[],"source":["!pip install lime\n","\n","import pandas as pd\n","import re\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import classification_report, confusion_matrix\n","from sklearn.pipeline import make_pipeline\n","from lime.lime_text import LimeTextExplainer"]},{"cell_type":"markdown","metadata":{"id":"DnQUec8ELn4l"},"source":["## Mount Drive (ONLY USE IF WORKING ON GOOGLE COLAB)\n","If working on Google Colab, you can modify the PATH to the folder on which you uploaded the data on your Drive."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XQqqTr19cYYJ"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","PATH = \"https://raw.githubusercontent.com/mhjabreel/CharCnn_Keras/master/data/ag_news_csv/\""]},{"cell_type":"markdown","metadata":{"id":"xCj9RMkrLtAt"},"source":["## Data Loading"]},{"cell_type":"markdown","metadata":{"id":"kdlGAlO97-Ss"},"source":["Download the train.csv & test.csv datasets from github ([link](https://github.com/mhjabreel/CharCnn_Keras/tree/master/data/ag_news_csv))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DvCYr1k_ABWd"},"outputs":[],"source":["import os \n","\n","df_train = pd.read_csv(os.path.join(PATH,\"train.csv\"), header = None)\n","df_test = pd.read_csv(os.path.join(PATH,\"test.csv\"), header = None)"]},{"cell_type":"markdown","metadata":{"id":"bJ46NfCCLzdz"},"source":["## Columns name cleaning"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gohYEUF1AYpa"},"outputs":[],"source":["# TODO : \n","#   - Rename the first column as \"target\", the 2nd as \"title\", the third as \"description\"\n","#   - Lower the text"]},{"cell_type":"markdown","metadata":{"id":"cjNEMXGxMlZm"},"source":["## TF-IDF Vectorizer & Logistic Regression "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zRsAmkfKUUn1"},"outputs":[],"source":["#TF-IDF\n","tfidf_vc = TfidfVectorizer(\n","    min_df = 10, \n","    max_features = 100000, \n","    analyzer = \"word\", \n","    ngram_range = (1, 2), \n","    stop_words = 'english', \n","    lowercase = True\n",")\n","\n","# Logistic Regression\n","model = LogisticRegression(C = 0.5, solver = \"sag\")\n","\n","# Pipeline definition\n","pipe = make_pipeline(tfidf_vc, model)\n","\n","# Pipeline training\n","pipe.fit(df_train[\"description\"], df_train.target)\n","\n","# Predictions on test_set\n","test_pred = pipe.predict(df_test[\"description\"])"]},{"cell_type":"markdown","metadata":{"id":"X5MNTpdlyA0H"},"source":["## Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WrJj6kbwx9uV"},"outputs":[],"source":["print(classification_report(df_test.target, test_pred))\n","print(confusion_matrix(df_test.target, test_pred))"]},{"cell_type":"markdown","metadata":{"id":"8eGjREQaNbuH"},"source":["## Explicability with LIME"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-1C6x8-4HNHH"},"outputs":[],"source":["# idx = ??? TO FILL\n","\n","class_names = [\"World\", \"Sports\", \"Business\", \"Sci/Tech\"]\n","explainer = LimeTextExplainer(class_names = class_names)\n","exp = explainer.explain_instance(\n","    df_test[\"description\"][idx], \n","    # TO FILL  \n","    num_features = 10, \n","    top_labels=3\n",")\n","\n","exp.show_in_notebook(text=df_test[\"description\"][idx])"]},{"cell_type":"markdown","metadata":{"id":"m_MGNfcJTS1E"},"source":["# LIME for image\n","\n","LIME algorithm for images works a little differently than for tabular data and text. Indeed, perturbing individual pixels one by one will not really change the prediction because more than one pixel contribute to one class. \n","\n","\n","\n","## Algorithm steps \n","The different steps computed by the algorithm are the following :\n","\n","### 1. Creation of superpixels : \n","The alorithm first requires to generate \"superpixels\" which are composed of contigous pixels that share properties such as texture or color distribution.This step is crucial for the generation of the LIME explanation since perturbation of superpixels is used to identify which of the image areas has been relevant for a specific class decision.\n","\n","LIME uses the quickshift algorithm to produce these superpixels (more details here : https://www.robots.ox.ac.uk/~vedaldi/assets/pubs/vedaldi08quick.pdf)\n","\n","<p align=\"center\">\n","<img src=https://www.oreilly.com/content/wp-content/uploads/sites/2/2019/06/figure3-2cea505fe733a4713eeff3b90f696507.jpg width=500>\n","</p>\n","\n","\n","### 2. Generate perturbed instances :\n","Once the superpixels are defined, we can generate a new dataset of perturbed instances by turning off superpixels on the image. The interpretable representation of the image is a binary vector where 1 indicates the original super-pixel and 0 indicates a grayed out super-pixel.\n","\n","### 3. Fit a linear model on the samples\n","\n","We can now fit a linear model on the perturbed instance to a specific class and highlight the superpixels with positive or negative weight towards a specific class.\n","\n","<p align=\"center\">\n","<img src=https://www.oreilly.com/content/wp-content/uploads/sites/2/2019/06/figure4-99d9ea184dd35876e0dbae81f6fce038.jpg width=500>\n","</p>\n","\n","\n","# Now let's practice !\n","\n","## Packages installation & Imports \n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DDsDzZNlTPaO"},"outputs":[],"source":["from tensorflow.keras.applications.inception_v3 import InceptionV3\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from lime import lime_image\n","from skimage.segmentation import mark_boundaries\n","from keras.applications import inception_v3 as inc_net"]},{"cell_type":"markdown","metadata":{"id":"R0FyQuA7TZ3Q"},"source":["## Load pre-trained InceptionV3 model and images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1WXAJZxoTPfz"},"outputs":[],"source":["# Load model\n","inception_model = InceptionV3(weights='imagenet')"]},{"cell_type":"markdown","metadata":{"id":"j4Efn6QfTi5Z"},"source":["### TODO : Here you can download any images and identify the way to access them on your computer / on drive"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dvGmMMGLTPi3"},"outputs":[],"source":["# Image processing\n","def transform_img_fn(path_list):\n","    out = []\n","    for img_path in path_list:\n","        img = image.load_img(img_path, target_size=(299, 299))\n","        x = image.img_to_array(img)\n","        x = np.expand_dims(x, axis=0)\n","        x = inc_net.preprocess_input(x)\n","        out.append(x)\n","    return np.vstack(out)\n","\n","## TODO : apply transform_img_fn on 3 images and affect the result to a list of images called \"images\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1xej91BUTPl0"},"outputs":[],"source":["# display the image\n","plt.imshow(images[0] / 2 + 0.5)\n","plt.axis('off')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"Bm8ILUEHTipb"},"source":["## Make some predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c08vwHNETgdk"},"outputs":[],"source":["# TODO: \n","# With de decode_predictions function print the 5 most probable classes into a list of tuples (class, description, probability)\n","preds = inception_model.predict(images)\n","for x in decode_predictions(preds)[0]:\n","    print(x)"]},{"cell_type":"markdown","metadata":{"id":"km8zL3IyTozx"},"source":["## Explicability with LIME image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qX8tP21mTPtT"},"outputs":[],"source":["# TODO: play with the different parameters\n","\n","# Train lime image explainer\n","explainer = lime_image.LimeImageExplainer()\n","explanation = explainer.explain_instance(images[0].astype('double'), inception_model.predict, top_labels=\"?\", hide_color=\"?\", num_samples=\"?\")\n","\n","# Plot boundaries\n","temp, mask = explanation.get_image_and_mask(explanation.top_labels[\"?\"], positive_only=\"?\", num_features=\"?\", hide_rest=\"?\")\n","plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))"]},{"cell_type":"markdown","metadata":{"id":"QkgSjPadTi5a"},"source":["## Plotting the heatmap"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aJUGfMHITpr_"},"outputs":[],"source":["# TODO : Select the same class explained on the figures above and return it as a variable called \"ind\"\n","\n","# TODO : What does explanation.local_exp[ind] return ? \n","\n","# TODO : Map each explanation weight to the corresponding superpixel and return it as a dict called dict_heatmap\n","\n","\n","\n","heatmap = np.vectorize(dict_heatmap.get)(explanation.segments) \n","\n","#Plot. The visualization makes more sense if a symmetrical colorbar is used.\n","plt.imshow(heatmap, cmap = 'RdBu', vmin  = -heatmap.max(), vmax = heatmap.max())\n","plt.colorbar()"]},{"cell_type":"markdown","metadata":{"id":"wws_aYMSYKJi"},"source":["# **SH**apley **A**dditive ex**P**lanations ([Lundberg et .al 2017](https://arxiv.org/abs/1905.04610))\n","\n","## From Game Theory\n","\n","\n","* In game theory, the [Shapley value](https://en.wikipedia.org/wiki/Shapley_value) (1953) is a solution concept of fairly distributing both gains and costs to several actors working in coalition.\n","* The Shapley value applies primarily in situations when the contributions of each actor are unequal, but they work in cooperation with each other to obtain the payoff.\n","\n","You first start by identifying each player’s contribution when they play individually, when 2 play together, and when all 3 play together.\n","<p align=\"center\">\n","<img src=https://clearcode.cc/wp-content/uploads/2016/11/ABC-wide.png?ver=1478561348 width=500>\n","</p>\n","\n","Then, you need to consider all possible orders and calculate their marginal value – e.g. what value does each player add when player A enters the game first, followed by player B, and then player C.\n","Below are the 6 possible orders and the marginal value each player adds in the different combinations:\n","<p align=\"center\">\n","<img src=https://clearcode.cc/wp-content/uploads/2016/11/ABC-updated.png?ver=1479258642 width=500>\n","</p>\n","\n","Now that we have calculated each player’s marginal value across all 6 possible order combinations, we now need to add them up and work out the Shapley value (i.e. the average) for each player.\n","\n","<ins>Example for Player A:</ins>\n","$ \\text{Shapley}_{value} = \\frac{7+7+10+3+9+10}{6} \\approx 7.7$\n","\n","Computing the Shapley value for each player will give the true contribution each player made to the game and assign credit fairly\n","\n","## To Explainability Method\n","\n","* Each value of an independent variable or a feature for a given sample is a part of a cooperative game where we assume that prediction is actually the payout.\n","* Shapley values correspond to the contribution of each feature towards pushing the prediction away from the expected value.\n","\n","Let take an example of a local prediction of a house price and see how the different features are impacting the prediction. \n","<p align=\"center\">\n","<img src=https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/boston_waterfall.png width=700>\n","</p>\n","\n","Example of features definition: \n","* LSTAT (% of lower status population)\n","* RM (average number of rooms per house in an area)\n","* NOX (nitric oxides concentration)\n","* RAD (index of accessibility to radial highways)\n","* For more information, link to [Boston dataset](https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html) \n"]},{"cell_type":"markdown","metadata":{"id":"RbpyrYIeeBtZ"},"source":["## Explanation of SHAP through visualization\n","\n","### Global explainability & local explanation summary\n","<p align=\"center\">\n","<img src=https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/boston_global_bar.png width=470>\n","<img src=https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/boston_beeswarm.png width=530>\n","</p>\n","\n","### Local explainability and correlation\n","<p align=\"center\">\n","<img src=https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/boston_scatter.png width=500>\n","</p>\n","\n","## Advantages\n","* SHAP has a solid theoretical foundation in game theory. The prediction is fairly distributed among the feature values. We get contrastive explanations that compare the prediction with the average prediction.\n","* SHAP connects LIME and Shapley values.\n","* SHAP has a fast implementation for tree-based models.\n","* When computation of the many Shapley values is possible, global model interpretations can be built. The global interpretation methods include feature importance, feature dependence, interactions, clustering and summary plots.\n","\n","## Drawbacks\n","* Slow computation if you want to compute Shapley values for many instances (except for tree-based models).\n","* The disadvantages of Shapley values also apply to SHAP: Shapley values can be misinterpreted.\n","* Since every model is trained from observational data, it is not necessarily a causal model.\n","\n","For more information on SHAP values see: https://github.com/slundberg/shap"]},{"cell_type":"markdown","metadata":{"id":"NvTx8iJFgyJI"},"source":["## Practical exercise\n","\n","Download the dataset from Kaggle ([link](https://www.kaggle.com/paololol/league-of-legends-ranked-matches))\n","\n","The objective in a game of League of Legends is to destroy the enemy base, in a 5 vs. 5 match. Using datasets with statistics of the game and the players, the goal is to predict the probability to win the game. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FBsbQvdldRLb"},"outputs":[],"source":["import pandas as pd\n","import numpy as np \n","import xgboost as xgb\n","from sklearn.model_selection import train_test_split\n","import shap\n","import matplotlib.pyplot as plt\n","\n","shap.initjs()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KJp0I7THgz61"},"outputs":[],"source":["# TODO : \n","# - read the data from matches.csv, participants.csv, stats1.csv, stats2.csv into matches participants stats1 and stats2 DataFrame. \n","# - concat stats1 and stats2 into a stats DataFrame \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AGkb7LanTi5c"},"outputs":[],"source":["# TODO : Explore the DataFrames"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mEacy-XsTi5c"},"outputs":[],"source":["# TODO : merge matches participants and stats into a single DataFrame called allstats"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"siJon9O_Ti5c"},"outputs":[],"source":["# TODO : drop games that lasted less than 10 minutes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JlAiCWA8Ti5d"},"outputs":[],"source":["# TODO : which columns are string-based categories ? "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OonvR16lTi5d"},"outputs":[],"source":["# TODO : Except for wardsbought, convert string-based categories to numeric values. \n","# ints : use df[col].astype('category') and get the codes of the categories "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fJJiWI6zTi5d"},"outputs":[],"source":["# TODO : Reduce dataset size to accelerate training filetring matchid lower than 50000"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yYIaQx5VTi5d"},"outputs":[],"source":["# TODO : Return an X DataFrame after removing the \"win\" column and a y Serie corresponding to the \"win\" colmun"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"usVtcWWJrc31"},"outputs":[],"source":["# convert all following features we want to consider as rates\n","rate_features = [\n","    \"kills\", \"deaths\", \"assists\", \"killingsprees\", \"doublekills\",\n","    \"triplekills\", \"quadrakills\", \"pentakills\", \"legendarykills\",\n","    \"totdmgdealt\", \"magicdmgdealt\", \"physicaldmgdealt\", \"truedmgdealt\",\n","    \"totdmgtochamp\", \"magicdmgtochamp\", \"physdmgtochamp\", \"truedmgtochamp\",\n","    \"totheal\", \"totunitshealed\", \"dmgtoobj\", \"timecc\", \"totdmgtaken\",\n","    \"magicdmgtaken\" , \"physdmgtaken\", \"truedmgtaken\", \"goldearned\", \"goldspent\",\n","    \"totminionskilled\", \"neutralminionskilled\", \"ownjunglekills\",\n","    \"enemyjunglekills\", \"totcctimedealt\", \"pinksbought\", \"wardsbought\",\n","    \"wardsplaced\", \"wardskilled\"\n","]\n","for feature_name in rate_features:\n","    X[feature_name] /= X[\"duration\"] / 60 # per minute rate\n","\n","# convert to fraction of game\n","X[\"longesttimespentliving\"] /= X[\"duration\"]\n","\n","# define friendly names for the features\n","full_names = {\n","    \"kills\": \"Kills per min.\",\n","    \"deaths\": \"Deaths per min.\",\n","    \"assists\": \"Assists per min.\",\n","    \"killingsprees\": \"Killing sprees per min.\",\n","    \"longesttimespentliving\": \"Longest time living as % of game\",\n","    \"doublekills\": \"Double kills per min.\",\n","    \"triplekills\": \"Triple kills per min.\",\n","    \"quadrakills\": \"Quadra kills per min.\",\n","    \"pentakills\": \"Penta kills per min.\",\n","    \"legendarykills\": \"Legendary kills per min.\",\n","    \"totdmgdealt\": \"Total damage dealt per min.\",\n","    \"magicdmgdealt\": \"Magic damage dealt per min.\",\n","    \"physicaldmgdealt\": \"Physical damage dealt per min.\",\n","    \"truedmgdealt\": \"True damage dealt per min.\",\n","    \"totdmgtochamp\": \"Total damage to champions per min.\",\n","    \"magicdmgtochamp\": \"Magic damage to champions per min.\",\n","    \"physdmgtochamp\": \"Physical damage to champions per min.\",\n","    \"truedmgtochamp\": \"True damage to champions per min.\",\n","    \"totheal\": \"Total healing per min.\",\n","    \"totunitshealed\": \"Total units healed per min.\",\n","    \"dmgtoobj\": \"Damage to objects per min.\",\n","    \"timecc\": \"Time spent with crown control per min.\",\n","    \"totdmgtaken\": \"Total damage taken per min.\",\n","    \"magicdmgtaken\": \"Magic damage taken per min.\",\n","    \"physdmgtaken\": \"Physical damage taken per min.\",\n","    \"truedmgtaken\": \"True damage taken per min.\",\n","    \"goldearned\": \"Gold earned per min.\",\n","    \"goldspent\": \"Gold spent per min.\",\n","    \"totminionskilled\": \"Total minions killed per min.\",\n","    \"neutralminionskilled\": \"Neutral minions killed per min.\",\n","    \"ownjunglekills\": \"Own jungle kills per min.\",\n","    \"enemyjunglekills\": \"Enemy jungle kills per min.\",\n","    \"totcctimedealt\": \"Total crown control time dealt per min.\",\n","    \"pinksbought\": \"Pink wards bought per min.\",\n","    \"wardsbought\": \"Wards bought per min.\",\n","    \"wardsplaced\": \"Wards placed per min.\",\n","    \"turretkills\": \"# of turret kills\",\n","    \"inhibkills\": \"# of inhibitor kills\",\n","    \"dmgtoturrets\": \"Damage to turrets\"\n","}\n","feature_names = [full_names.get(n, n) for n in X.columns]\n","X.columns = feature_names"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ufCmizXxmOmh"},"outputs":[],"source":["# create train/validation split\n","Xt, Xv, yt, yv = train_test_split(X,y, test_size=0.2, random_state=10)\n","dt = xgb.DMatrix(Xt, label=yt.values)\n","dv = xgb.DMatrix(Xv, label=yv.values)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ratjSrM_nh3c"},"outputs":[],"source":["# We want to solve a logistic regression with a logloss evaluation\n","params = {\n","    \"eta\": 0.5,\n","    \"max_depth\": 4,\n","    \"objective\": 'binary:logistic',\n","    \"silent\": 1,\n","    \"base_score\": np.mean(yt),\n","    \"eval_metric\": 'logloss'\n","}\n","# TODO : with xgb.train method, code the training part for 300 iterations with early stopping rounds at 5 and a verbose eval at 25\n","model = \"?\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_J-o4zTHnj3z"},"outputs":[],"source":["# compute the SHAP values for every prediction in the validation dataset\n","explainer = shap.TreeExplainer(model)\n","shap_values = explainer.shap_values(Xv)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ejoFle1lnn2W"},"outputs":[],"source":["# Force plot example for a record\n","shap.initjs()\n","shap.force_plot(explainer.expected_value, shap_values[0,:], Xv.iloc[0,:])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rgOkFff6noid"},"outputs":[],"source":["xs = np.linspace(-4,4,100)\n","plt.xlabel(\"Log odds of winning\")\n","plt.ylabel(\"Probability of winning\")\n","plt.title(\"How changes in log odds convert to probability of winning\")\n","plt.plot(xs, 1/(1+np.exp(-xs)))\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gSshOsjou1UH"},"outputs":[],"source":["# Global explainability\n","shap.plots.bar(explainer(Xv))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z_50_teunroK"},"outputs":[],"source":["# Local explanation summary\n","shap.summary_plot(shap_values, Xv)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7vJ6WjzVohjr"},"outputs":[],"source":["# Dependence plot between variables (automatic)\n","shap.dependence_plot(\"Gold earned per min.\", shap_values, Xv)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bhqwIxjent6R"},"outputs":[],"source":["# Dependence plot between variables (assigned)\n","shap.dependence_plot(\"Gold earned per min.\", shap_values, Xv, alpha=0.2, interaction_index=\"Deaths per min.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"10fT0tR5nvyS"},"outputs":[],"source":["# TODO : sort the features indexes by their importance in the model and return them in top_inds list\n","\n","\n","# TODO : with shap.dependence_plot(), make SHAP plots of the three most important features\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LL0iolJYn0_D"},"outputs":[],"source":["# Play with plot variables\n","shap.dependence_plot(\"id\", shap_values, Xv, x_jitter=\"?\", alpha=\"?\", dot_size=\"?\")"]},{"cell_type":"markdown","metadata":{"id":"vUhOGswOTi5g"},"source":["## Bonus Section: Chest X-Ray Images\n","\n","> In recent years, convolutional neural networks have been widely used in image recognition tasks and have obtained excellent results. A team of radiologists who wish to be helped in the detection of pneumonia on chest X-ray images have called on a team of data scientists to train a convolutional neural network capable of determining whether a X-ray is that of a patient with pneumonia or not.\n",">\n","> However, before using it to be assisted on a daily basis by this model, they want to ensure its relevance. It is essential for them that the model uses the lung region to determine whether a patient has pneumonia or not.\n",">\n","> The trained model has been saved in the h5 format and is named **model.h5**. You have access to the images used to test the model in the directory named **test**.\n",">\n","> Your task will involve two aspects:\n",">* Determine if the model is relevant from a medical point of view.\n",">* If necessary, propose an approach to make the model more relevant."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"noDmfNLPTi5g"},"outputs":[],"source":["# load trained model\n","\n","from keras.models import load_model\n","\n","model = load_model(\"/content/gdrive/MyDrive/.../model.h5\")"]},{"cell_type":"markdown","metadata":{"id":"tZe1HUtXtMwL"},"source":["## Going further with Explainability\n","\n","### SHAPASH ([Github](https://github.com/MAIF/shapash))\n","\n","A module developped by MAIF using SHAP methodology with nice features such as a web app for exploration and ML OPS usage.\n","\n","[Demo](https://shapash-demo.ossbymaif.fr/) of the dashboarding capabilities.\n","\n","[Notebook](https://github.com/MAIF/shapash/blob/master/tutorial/tutorial03-Shapash-overview-model-in-production.ipynb) example for ML OPS usage\n","\n","#### Strengths \n","* A great tool for data scientists to investigate a model's behaviour faster ! \n","* Ongoing development today to add new features \n","\n","#### Weaknesses\n","* It \"just\" a plotly layer on top of SHAP not a end-user-driven Framework for model explanations\n","* Decision making based on the graphs is not immediate, it only provides insights \n","* Audiences need to be a bit technical to be confortable with the approach "]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"explain","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"vscode":{"interpreter":{"hash":"7ebd9eab2253b0a92e377a82adc134eb1dde96a267d4c1eca70b0bd753ed0b6b"}}},"nbformat":4,"nbformat_minor":0}
